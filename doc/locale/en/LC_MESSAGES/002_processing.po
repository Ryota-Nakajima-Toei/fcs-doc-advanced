# SOME DESCRIPTIVE TITLE.
# Copyright (C) TOEI Zukun
# This file is distributed under the same license as the FCS Doc Advanced
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: FCS Doc Advanced latest\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-10-31 10:54+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: en\n"
"Language-Team: en <LL@li.org>\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../002_processing.md:1
msgid "FCS内部の処理"
msgstr "FCS Internal Processing"

#: ../../002_processing.md:2
msgid "このページでは、アクターの画像から表情をトラッキングし、キャラクターの表情を出力するまでの流れについて説明します。"
msgstr "In this page, we explains FCS processing, from tracking the actor's facial expressions in video images to outputting the character's expressions."

#: ../../002_processing.md:8
msgid ""
"アクターの画像に対しフェイシャルトラッキングを実行し (1) 、　 顔の向きの補正 (2) やトラッキング情報を取捨選択 (3) の後、 "
"キャラクターの表情が出力されます (4) 。"
msgstr "Perform tracking on the actor's facial images (1). After correcting the head orientation (2), and selecting / filtering the tracking information (3), output the character's expression (4)."

#: ../../002_processing.md:19
msgid "1. フェイシャルトラッキング"
msgstr "1．Facial Tracking"

#: ../../002_processing.md:21
msgid ""
"まず、画像からアクターの表情を取得するためにフェイシャルトラッキングを実行します。FCSのオートトラッキング機能では、画像に対してアクターの顔の3次元モデル（アクターモデル）を構築します。これにより、目や口の輪郭や鼻の位置を表す点（ランドマーク）の座標や、表情パラメータ（ARKitブレンドシェイプ）といった情報を取得します。"
"   "
"トラッキングに使用するモデルはパイプラインによって異なり、パイプライン名に\"+\"がついているものはツークン研究所の新規独自モデルになります。"
msgstr "First, facial tracking is started to obtain the actor's facial expression from video images. The FCS auto-tracking system generates the 3D model of the actor's face (actor model) based on video image. As a result, we get facial information, such as the coordinates of contours points of the actor's eyes and mouth, and the position of the nose (landmarks), as well as expression parameters (ARKit blendshapes).<br><br>The 3D model used for facial tracking varies by pipeline; pipelines with "+" in their name utilize a new proprietary model developed by TOEI Zukun Laboratory."

#: ../../002_processing.md:40
msgid "2. 顔の向きを補正"
msgstr "2．Correct Face Orientation"

#: ../../002_processing.md:42
msgid "激しい動作を伴う演技では、カメラの揺れなどにより動画における顔の位置がずれることがしばしば発生します。また、休憩などでカメラを着脱することによりカメラの装着位置が変化してしまい、動画における顔の位置がプロファイルにおける位置からずれてしまうこともあります。このようなカメラの揺れや位置変化による影響を軽減するために、パイプライン名に\"RP\"が入っているパイプラインでは、顔の向きがNeutralのプロファイルと同じ向きになるように補正します。"
msgstr "In performances involving intense movement, the actor's face often shifts position in the video due to factors like camera shake. Furthermore, removing and reattaching the camera (e.g., during breaks) can change its mounting position, causing the face's position in the video to shift relative to its position in the tracking profiles. To mitigate the effects of such camera shake and position changes, the pipeline called “RP” applies a correction process so that the face orientation aligns with Neutral profile orientation."

#: ../../002_processing.md:49
msgid "3. トラッキング情報の取捨選択"
msgstr "3．Select / Filter Tracking Information"

#: ../../002_processing.md:51
msgid "FCSはユーザーのキャラクターモデルの内部構造を直接参照していないので、どのコントローラーが顔のどの部分に対応しているかという情報を自動的に取得できません。そのため、コントローラー値への変換に使用されるトラッキング情報には、目的のコントローラーとは関係ない動きが含まれている場合があります。"
msgstr "FCS cannot automatically determine which controller corresponds to which facial parts of the actor, because it does not directly reference the internal structure of the user-registered character model. Therefore, facial tracking information used during the conversion to controller values may contain movements unrelated to the target controller."

#: ../../002_processing.md:53
msgid "そこでより精度を高めるために、FCSにはコントローラーごとのブレンドシェイプ選択機能を搭載しています。これにより、各コントローラーに関連するブレンドシェイプとそれに伴い変位するランドマークを手動で限定することができ、コントローラー値への変換に使用されるトラッキング情報を絞ることができます。"
msgstr "To further improve accuracy, FCS is equipped with ARKit blendshapes selection settings for each controller. This allows for manually limiting blendshapes relevant to each controller and the landmarks that consequently change position, thereby narrowing down the tracking information used for conversion to controller values."

#: ../../002_processing.md:55
msgid "※このブレンドシェイプ選択機能はオプショナルな機能であり、設定をしなくても問題なく動作するため、迷った場合はデフォルト設定での使用を推奨します。"
msgstr "※Blendshape selection settings is optional, and FCS operates correctly without this settings; therefore, if you are unsure, we recommend using default settings."

#: ../../002_processing.md:58
msgid "ブレンドシェイプの選択方法"
msgstr "How to use blendshapes settings"

#: ../../002_processing.md:60
msgid "ControllerウィンドウにあるControllerテーブルのヘッダーを右クリックするとコンテキストメニューが表示されるので、\"blendshapes\"の設定を有効化し、コントローラーに対してブレンドシェイプを選択します。設定を完了後、Saveボタンを押して保存します。"
msgstr "In Controller window, right-click the header of Controller table to display the context menu. Then, enable the "blendshapes" setting and select the blendshapes for the controller. Once settings are complete, click the "Save" button to save them."

#: ../../002_processing.md:66
msgid "Controllerウィンドウで、\"blendshapes\"の設定を有効化"
msgstr "In Controller window, enable the “blendshapes” settings."

#: ../../002_processing.md:73
msgid "コントローラーに対して、ブレンドシェイプを選択し、設定する"
msgstr "Select blendshapes and save settings for facial controller."

#: ../../002_processing.md:85
msgid "4. キャラクターの表情に変換"
msgstr "4．Convert To Character Facial Expressions"

#: ../../002_processing.md:91
msgid ""
"最後にアクターの表情をキャラクターの表情に変換してアニメーションを出力します。この変換プロセスの説明はあくまでイメージであり、実際の計算とは異なる場合があります。"
" "
"まず、ここまでの工程で得られるアクターの表情に対して、類似するプロファイルを選出しその比率を計算します。その後、それぞれのプロファイルに対応したキャラクターの表情を、計算された比率に応じてブレンドすることで、アクターの表情をキャラクターの表情へと変換します。"
msgstr "Finally, the actor's facial expressions are converted into the character's facial expressions, and the animation is output. The figure below illustrates a general overview of conversion process, but this is an conceptual image, and may differ from actual calculation.<br><br>First, we select similar profiles and calculate their ratio based on the actor's expressions obtained from the processes described up to this point. Next, the actor's expressions are converted into the character's expressions by blending the corresponding character profiles according to the calculated ratios."

#: ../../002_processing.md:98
msgid "類似するプロファイルの比率からキャラクターの表情をブレンド"
msgstr "Blend and output character expressions, based on the ratio of similar profiles."

#~ msgid "ControllerウィンドウにあるControllerテーブルのヘッダーを右クリックするとコンテキストメニューが表示されるので、"
#~ msgstr ""

#~ msgid "\"blendshape\"を有効化し"
#~ msgstr ""

#~ msgid "設定したいコントローラーを選択しブレンドシェイプを設定 ※最後にコントローラーの設定を保存する必要があります。"
#~ msgstr ""

